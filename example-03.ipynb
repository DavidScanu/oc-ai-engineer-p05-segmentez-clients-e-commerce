{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recommended strategy on how to establish a baseline RFM segmentation\n",
    "\n",
    "Below is an overview of one recommended strategy, along with a code example, that explains how to establish a baseline RFM segmentation model using k-means and how to monitor drift to decide when to retrain. In summary, the strategy involves:\n",
    "\n",
    "1. **Establishing a Baseline Model:**\n",
    "   - **Data Aggregation & Preprocessing:**  \n",
    "     Aggregate your raw orders over a defined “stable” period (for example, the first 12 months of the 2-year period) to compute the RFM metrics (recency, frequency, monetary).\n",
    "   - **Feature Scaling & Pipeline Consistency:**  \n",
    "     Standardize (or otherwise scale) your features and save your transformation pipeline. This is crucial so that you can apply the exact same transformation to new data.\n",
    "   - **Clustering & Model Storage:**  \n",
    "     Train your k-means clustering model (using techniques like k-means++ initialization and a fixed random state for reproducibility) and compute baseline quality metrics (e.g., inertia, silhouette score, and cluster distribution). Save the cluster centroids and other model parameters.\n",
    "\n",
    "2. **Monitoring for Drift:**\n",
    "   - **Regular Aggregation on a Rolling Basis:**  \n",
    "     For subsequent time periods (e.g., monthly or quarterly), aggregate new orders into RFM metrics for the same customers (or new ones if needed).  \n",
    "   - **Comparing Distributions & Metrics:**  \n",
    "     - **Statistical Tests:** Use tests like the Kolmogorov–Smirnov test or calculate the Population Stability Index (PSI) on each RFM feature to detect shifts in their distributions.\n",
    "     - **Quality Metrics:** Compare the new aggregated data’s clustering quality (e.g., inertia, silhouette score) against the baseline.\n",
    "     - **Cluster Center Movements:** If possible, compare the positions of the new cluster centers (or the assigned clusters using the baseline model) to the baseline centroids.  \n",
    "     - **Label Comparison (when applicable):** If the same customers are present in both periods, you can use metrics such as the Adjusted Rand Index (ARI) or homogeneity and completeness scores to evaluate if the cluster assignments are remaining similar.\n",
    "     \n",
    "3. **Deciding When to Retrain:**\n",
    "   - **Threshold-Based Alerts:**  \n",
    "     Define thresholds for relative changes in metrics (for example, a 20% change in inertia or silhouette score, or significant shifts in feature distributions). When these thresholds are exceeded, it indicates that customer behavior has shifted and that the model may no longer represent the current state.\n",
    "   - **Evaluate the Frequency:**  \n",
    "     By monitoring these metrics on a rolling window (say monthly or quarterly), you can analyze how quickly your metrics drift. This analysis can help you determine the optimal frequency for retraining—if you see that significant drift happens every 3–4 months, then quarterly retraining might be ideal.\n",
    "   - **Business Cycle Considerations:**  \n",
    "     In some industries, seasonal effects (holidays, promotions, etc.) might suggest aligning model updates with business cycles.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation\n",
    "\n",
    "1. **Baseline Model Establishment:**  \n",
    "   - We aggregate orders over the first 12 months to create the baseline RFM table.\n",
    "   - We scale the features and train a k-means model (with fixed random state for reproducibility) on the baseline data.\n",
    "   - Baseline quality metrics such as inertia, silhouette score, and cluster distribution are computed and stored.\n",
    "\n",
    "2. **Drift Monitoring:**  \n",
    "   - On a rolling basis (in this example, every 3 months after the baseline), **we re-aggregate the orders** up to the current period and compute new RFM values.\n",
    "   - We transform the new data using the same scaler and either use the baseline model for cluster assignment or retrain a new k-means model for comparison.\n",
    "   - We compare the new clustering’s **inertia, silhouette score, and distribution** against the baseline.\n",
    "   - We also compare the clustering labels for the common set of customers using **ARI, homogeneity, and completeness**.\n",
    "   - The **Kolmogorov–Smirnov** test is used to assess shifts in the distribution of each RFM feature.\n",
    "   - The distance between baseline and new cluster centers is computed to quantify shifts.\n",
    "\n",
    "3. **Evaluating Retraining Frequency:**  \n",
    "   - By reviewing how these drift metrics change over successive periods, you can identify the cadence at which significant changes occur.\n",
    "   - If the metrics (or thresholds) indicate significant drift (for example, over a 20% change in inertia or silhouette score), that’s a signal to retrain.\n",
    "   - The monitoring frequency (monthly, quarterly, etc.) should be chosen based on the rate of change observed and business cycle considerations.\n",
    "\n",
    "This strategy ensures that your baseline RFM segmentation model remains representative of your customer behavior and that you have an objective method to decide when retraining is warranted.\n",
    "\n",
    "---\n",
    "\n",
    "Below is a Python example that demonstrates these concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RFM (first few rows):\n",
      "                    recency  frequency    monetary\n",
      "customer_unique_id                                \n",
      "1                        25          3   86.329042\n",
      "2                       328          1  127.805743\n",
      "3                       210          2  102.044041\n",
      "4                        20          3  229.920447\n",
      "5                         7          4  906.574205\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, homogeneity_score, completeness_score\n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===============================\n",
    "# STEP 1: Establishing a Baseline Model\n",
    "# ===============================\n",
    "\n",
    "# Assume orders data over 2 years with columns: customer_unique_id, order_date, amount\n",
    "# For demonstration, we simulate data.\n",
    "\n",
    "np.random.seed(42)\n",
    "n_customers = 200\n",
    "n_orders = 1000\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2024, 12, 31)\n",
    "date_range = (end_date - start_date).days\n",
    "\n",
    "# Simulated orders\n",
    "orders = pd.DataFrame({\n",
    "    'customer_unique_id': np.random.choice(range(1, n_customers+1), size=n_orders),\n",
    "    'order_date': [start_date + timedelta(days=int(np.random.rand()*date_range)) for _ in range(n_orders)],\n",
    "    'amount': np.random.exponential(scale=100, size=n_orders)  # some variability in spend\n",
    "})\n",
    "\n",
    "# Define baseline period (for example, first 12 months)\n",
    "baseline_end = start_date + timedelta(days=365)\n",
    "baseline_orders = orders[orders['order_date'] <= baseline_end]\n",
    "\n",
    "# Compute RFM metrics for baseline period\n",
    "# - Recency: days since last order relative to baseline_end\n",
    "# - Frequency: number of orders in baseline period\n",
    "# - Monetary: total spend in baseline period\n",
    "\n",
    "rfm_baseline = baseline_orders.groupby('customer_unique_id').agg({\n",
    "    'order_date': lambda x: (baseline_end - x.max()).days,\n",
    "    'customer_unique_id': 'count',\n",
    "    'amount': 'sum'\n",
    "}).rename(columns={\n",
    "    'order_date': 'recency',\n",
    "    'customer_unique_id': 'frequency',\n",
    "    'amount': 'monetary'\n",
    "})\n",
    "\n",
    "print(\"Baseline RFM (first few rows):\")\n",
    "print(rfm_baseline.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm_baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Clustering Metrics:\n",
      "Inertia: 160.98940763117378\n",
      "Silhouette Score: 0.3368236192887641\n",
      "Cluster Distribution:\n",
      " cluster\n",
      "0    0.307263\n",
      "1    0.223464\n",
      "2    0.145251\n",
      "3    0.324022\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: scale features\n",
    "features = ['recency', 'frequency', 'monetary']\n",
    "scaler = StandardScaler()\n",
    "X_baseline = scaler.fit_transform(rfm_baseline[features])\n",
    "\n",
    "# Train k-means on baseline data\n",
    "k = 4  # or choose via domain knowledge / elbow method\n",
    "kmeans_baseline = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "rfm_baseline['cluster'] = kmeans_baseline.fit_predict(X_baseline)\n",
    "\n",
    "# Compute baseline quality metrics\n",
    "baseline_inertia = kmeans_baseline.inertia_\n",
    "baseline_silhouette = silhouette_score(X_baseline, rfm_baseline['cluster'])\n",
    "baseline_distribution = rfm_baseline['cluster'].value_counts(normalize=True).sort_index()\n",
    "\n",
    "print(\"\\nBaseline Clustering Metrics:\")\n",
    "print(\"Inertia:\", baseline_inertia)\n",
    "print(\"Silhouette Score:\", baseline_silhouette)\n",
    "print(\"Cluster Distribution:\\n\", baseline_distribution)\n",
    "\n",
    "# Save the baseline model parameters: scaler and cluster centers\n",
    "baseline_centers = kmeans_baseline.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# STEP 2: Monitoring for Drift on New Data Periods\n",
    "# ===============================\n",
    "\n",
    "def aggregate_rfm(orders_df, period_end):\n",
    "    \"\"\"\n",
    "    Aggregate orders into RFM for each customer up to a given period_end date.\n",
    "    \"\"\"\n",
    "    rfm = orders_df[orders_df['order_date'] <= period_end].groupby('customer_unique_id').agg({\n",
    "        'order_date': lambda x: (period_end - x.max()).days,\n",
    "        'customer_unique_id': 'count',\n",
    "        'amount': 'sum'\n",
    "    }).rename(columns={\n",
    "        'order_date': 'recency',\n",
    "        'customer_unique_id': 'frequency',\n",
    "        'amount': 'monetary'\n",
    "    })\n",
    "    return rfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2024, 3, 31, 0, 0),\n",
       " datetime.datetime(2024, 6, 29, 0, 0),\n",
       " datetime.datetime(2024, 9, 27, 0, 0),\n",
       " datetime.datetime(2024, 12, 26, 0, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For example, monitor drift every 3 months after the baseline period\n",
    "monitor_dates = [baseline_end + timedelta(days=90*i) for i in range(1, 5)]  # 90, 180, 270, 360 days later\n",
    "monitor_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Clustering Metrics:\n",
      "Inertia: 160.98940763117378\n",
      "Silhouette Score: 0.3368236192887641\n",
      "Cluster Distribution:\n",
      " cluster\n",
      "0    0.307263\n",
      "1    0.223464\n",
      "2    0.145251\n",
      "3    0.324022\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Monitoring for Drift ---\n",
      "\n",
      "--- Monitoring at period end: 2024-03-31 ---\n",
      "New Data Metrics:\n",
      "Inertia: 214.2919585453768\n",
      "Silhouette Score: 0.301222347461644\n",
      "Cluster Distribution:\n",
      " cluster_new\n",
      "0    0.111732\n",
      "1    0.201117\n",
      "2    0.374302\n",
      "3    0.312849\n",
      "Name: proportion, dtype: float64\n",
      "Adjusted Rand Index (ARI): 0.23563551366334912\n",
      "Homogeneity: 0.3968279302122142\n",
      "Completeness: 0.4102794116018595\n",
      "KS test for recency: statistic=0.061, p-value=0.889\n",
      "KS test for frequency: statistic=0.218, p-value=0.000\n",
      "KS test for monetary: statistic=0.145, p-value=0.046\n",
      "Distance Matrix between Baseline and New Cluster Centers:\n",
      "[[2.99187405 3.60334816 1.74446156 0.9287696 ]\n",
      " [1.12046353 4.06240232 2.84758721 1.31135911]\n",
      " [4.6786521  0.53910127 1.79862873 2.9131685 ]\n",
      " [3.48671388 2.13931313 0.55603562 1.25488077]]\n",
      "Significant change in cluster quality detected. Consider re-training the model.\n",
      "Inertia Change: 0.33109352781966245\n",
      "Silhouette Change: 0.10569707641731195\n",
      "\n",
      "--- Monitoring at period end: 2024-06-29 ---\n",
      "New Data Metrics:\n",
      "Inertia: 293.2208646704306\n",
      "Silhouette Score: 0.26072320688455486\n",
      "Cluster Distribution:\n",
      " cluster_new\n",
      "0    0.212291\n",
      "1    0.351955\n",
      "2    0.262570\n",
      "3    0.173184\n",
      "Name: proportion, dtype: float64\n",
      "Adjusted Rand Index (ARI): 0.12820180454068145\n",
      "Homogeneity: 0.1905897489475914\n",
      "Completeness: 0.18939334727824353\n",
      "KS test for recency: statistic=0.117, p-value=0.170\n",
      "KS test for frequency: statistic=0.352, p-value=0.000\n",
      "KS test for monetary: statistic=0.240, p-value=0.000\n",
      "Distance Matrix between Baseline and New Cluster Centers:\n",
      "[[2.562782   2.39699886 0.95558041 4.75205125]\n",
      " [0.92781834 3.08150322 1.9577519  5.14835045]\n",
      " [3.83765534 1.18376434 2.47985533 1.62447191]\n",
      " [2.75925974 1.00526034 0.70285196 3.29694358]]\n",
      "Significant change in cluster quality detected. Consider re-training the model.\n",
      "Inertia Change: 0.8213674364353131\n",
      "Silhouette Change: 0.22593549871859542\n",
      "\n",
      "--- Monitoring at period end: 2024-09-27 ---\n",
      "New Data Metrics:\n",
      "Inertia: 348.5775913227956\n",
      "Silhouette Score: 0.3164860783954698\n",
      "Cluster Distribution:\n",
      " cluster_new\n",
      "0    0.374302\n",
      "1    0.128492\n",
      "2    0.335196\n",
      "3    0.162011\n",
      "Name: proportion, dtype: float64\n",
      "Adjusted Rand Index (ARI): 0.10705947197021172\n",
      "Homogeneity: 0.15397127481625036\n",
      "Completeness: 0.15993872950417176\n",
      "KS test for recency: statistic=0.106, p-value=0.266\n",
      "KS test for frequency: statistic=0.447, p-value=0.000\n",
      "KS test for monetary: statistic=0.313, p-value=0.000\n",
      "Distance Matrix between Baseline and New Cluster Centers:\n",
      "[[1.52011476 6.18455828 3.3662231  3.35952744]\n",
      " [2.03191503 6.63437016 3.89182751 1.67280405]\n",
      " [2.18351172 3.00702122 0.72559247 4.24720501]\n",
      " [0.80015496 4.72535149 1.92603075 3.42729329]]\n",
      "Significant change in cluster quality detected. Consider re-training the model.\n",
      "Inertia Change: 1.1652206592460157\n",
      "Silhouette Change: 0.06038038821695153\n",
      "\n",
      "--- Monitoring at period end: 2024-12-26 ---\n",
      "New Data Metrics:\n",
      "Inertia: 389.90601755508663\n",
      "Silhouette Score: 0.3382350704239686\n",
      "Cluster Distribution:\n",
      " cluster_new\n",
      "0    0.189944\n",
      "1    0.318436\n",
      "2    0.458101\n",
      "3    0.033520\n",
      "Name: proportion, dtype: float64\n",
      "Adjusted Rand Index (ARI): 0.05404260855072279\n",
      "Homogeneity: 0.09893138189835907\n",
      "Completeness: 0.11538567872339213\n",
      "KS test for recency: statistic=0.145, p-value=0.046\n",
      "KS test for frequency: statistic=0.525, p-value=0.000\n",
      "KS test for monetary: statistic=0.374, p-value=0.000\n",
      "Distance Matrix between Baseline and New Cluster Centers:\n",
      "[[3.47737915 4.77375704 2.16839926 9.05870968]\n",
      " [1.91385541 5.19471195 2.64941581 9.36627748]\n",
      " [4.08902509 1.82022643 1.51712043 5.77436411]\n",
      " [3.40062389 3.35030498 0.92661012 7.58166899]]\n",
      "Significant change in cluster quality detected. Consider re-training the model.\n",
      "Inertia Change: 1.4219358484028968\n",
      "Silhouette Change: 0.004190475531926588\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBaseline Clustering Metrics:\")\n",
    "print(\"Inertia:\", baseline_inertia)\n",
    "print(\"Silhouette Score:\", baseline_silhouette)\n",
    "print(\"Cluster Distribution:\\n\", baseline_distribution)\n",
    "\n",
    "print(\"\\n--- Monitoring for Drift ---\")\n",
    "\n",
    "for monitor_date in monitor_dates:\n",
    "    print(f\"\\n--- Monitoring at period end: {monitor_date.date()} ---\")\n",
    "    # Aggregate new RFM data for current period\n",
    "    rfm_new = aggregate_rfm(orders, monitor_date)\n",
    "    # print(\"New RFM Shape:\", rfm_new.shape)\n",
    "    # print(rfm_new.iloc[0,:])\n",
    "    \n",
    "    # Align customers: use intersection of baseline and new customers for label-based comparisons\n",
    "    common_customers = rfm_baseline.index.intersection(rfm_new.index)\n",
    "    # print(\"Common Customers:\", len(common_customers))\n",
    "    rfm_new = rfm_new.loc[common_customers]\n",
    "    # print(\"New RFM Shape (after alignment):\", rfm_new.shape)\n",
    "    X_new = scaler.transform(rfm_new[features])\n",
    "    \n",
    "    # Option 1: Use the baseline k-means model to assign clusters (keeps the original segmentation)\n",
    "    rfm_new['cluster_baseline'] = kmeans_baseline.predict(X_new)\n",
    "    \n",
    "    # Option 2: Retrain a k-means on new data (to see the drift in cluster centers) \n",
    "    # Note: In production, you might not retrain until you decide to update.\n",
    "    kmeans_new = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    rfm_new['cluster_new'] = kmeans_new.fit_predict(X_new)\n",
    "    \n",
    "    new_inertia = kmeans_new.inertia_\n",
    "    new_silhouette = silhouette_score(X_new, rfm_new['cluster_new'])\n",
    "    new_distribution = rfm_new['cluster_new'].value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    print(\"New Data Metrics:\")\n",
    "    print(\"Inertia:\", new_inertia)\n",
    "    print(\"Silhouette Score:\", new_silhouette)\n",
    "    print(\"Cluster Distribution:\\n\", new_distribution)\n",
    "    \n",
    "    # Compare baseline vs. new clustering (only on common customers)\n",
    "    ari = adjusted_rand_score(rfm_baseline.loc[common_customers, 'cluster'], rfm_new['cluster_new'])\n",
    "    homogeneity = homogeneity_score(rfm_baseline.loc[common_customers, 'cluster'], rfm_new['cluster_new'])\n",
    "    completeness = completeness_score(rfm_baseline.loc[common_customers, 'cluster'], rfm_new['cluster_new'])\n",
    "    \n",
    "    print(\"Adjusted Rand Index (ARI):\", ari)\n",
    "    print(\"Homogeneity:\", homogeneity)\n",
    "    print(\"Completeness:\", completeness)\n",
    "    \n",
    "    # Compare feature distributions using KS test\n",
    "    for feature in features:\n",
    "        stat, p_value = ks_2samp(rfm_baseline.loc[common_customers, feature],\n",
    "                                  rfm_new[feature])\n",
    "        print(f\"KS test for {feature}: statistic={stat:.3f}, p-value={p_value:.3f}\")\n",
    "    \n",
    "    # Compare cluster centers distance\n",
    "    centers_new = kmeans_new.cluster_centers_\n",
    "    # Calculate Euclidean distances between baseline and new cluster centers\n",
    "    from scipy.spatial.distance import cdist\n",
    "    distance_matrix = cdist(baseline_centers, centers_new, metric='euclidean')\n",
    "    print(\"Distance Matrix between Baseline and New Cluster Centers:\")\n",
    "    print(distance_matrix)\n",
    "    \n",
    "    # Decide if drift is significant: you might define thresholds based on business rules or historical data.\n",
    "    inertia_change = abs(new_inertia - baseline_inertia) / baseline_inertia\n",
    "    silhouette_change = abs(new_silhouette - baseline_silhouette) / baseline_silhouette\n",
    "    if inertia_change > 0.2 or silhouette_change > 0.2:\n",
    "        print(\"Significant change in cluster quality detected. Consider re-training the model.\")\n",
    "    else:\n",
    "        print(\"No significant drift detected yet.\")\n",
    "    print(\"Inertia Change:\", inertia_change)\n",
    "    print(\"Silhouette Change:\", silhouette_change)\n",
    "\n",
    "# ===============================\n",
    "# STEP 3: Determining the Best Training Frequency\n",
    "# ===============================\n",
    "\n",
    "# By running the monitoring code above on a sliding window (e.g., every 3 months),\n",
    "# you can analyze how quickly your drift metrics (inertia, silhouette, feature distributions, cluster center shifts) change.\n",
    "#\n",
    "# For instance, if you observe that significant changes (exceeding your defined thresholds) occur every quarter,\n",
    "# then quarterly retraining might be optimal. If the drift is very gradual,\n",
    "# you might extend the retraining frequency to every 6 months.\n",
    "#\n",
    "# You can also supplement these metrics with business insights (e.g., seasonal campaigns, product changes)\n",
    "# to decide on the retraining frequency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection of customers\n",
    "\n",
    "You are excluding new customers from that particular label-based comparison. The main reason for doing so is that metrics like the Adjusted Rand Index (ARI), homogeneity, and completeness require comparing the clustering assignments on the same set of data points. Here’s why:\n",
    "\n",
    "1. **One-to-One Correspondence Requirement:**  \n",
    "   Metrics such as **ARI and others compare how each customer is clustered in both periods**. If a customer appears only in the new period (i.e., a new customer), there is no baseline cluster assignment available for that customer. This lack of a direct mapping makes the comparison invalid.\n",
    "\n",
    "2. **Ensuring Meaningful Comparisons:**  \n",
    "   By using only the intersection of customers present in both the baseline and new data, you ensure that you’re comparing \"apples to apples.\" This allows you to assess whether the clustering assignments for the same set of customers have changed over time, which is what these metrics are designed to measure.\n",
    "\n",
    "3. **Handling New Customers Separately:**  \n",
    "   While new customers are excluded from the label-based drift metrics, they’re still important for your overall analysis. You can monitor new customers by:\n",
    "   - Checking their distribution across clusters using the baseline model.\n",
    "   - Analyzing how the overall cluster proportions change when new customers are included.\n",
    "   - Evaluating business metrics (e.g., average spend, churn rate) for new versus existing customers.\n",
    "\n",
    "In practice, you might use two different analyses:\n",
    "- **Label-Based Comparison:** Restrict to customers present in both periods to use ARI, homogeneity, and completeness.\n",
    "- **Overall Drift Monitoring:** Analyze all customers (including new ones) to see how overall cluster characteristics and business metrics are evolving.\n",
    "\n",
    "This two-pronged approach ensures that you capture both the stability of the segmentation for existing customers and the integration and behavior of new customers over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregating all past data\n",
    "\n",
    "Great question! The choice between **aggregating all past data (2023 + Q1 2024)** versus using a **rolling window (e.g., baseline 2023, new data Q1 2024 only)** for drift monitoring depends on the assumptions you make about customer behavior and the stability of your clusters.  \n",
    "\n",
    "---\n",
    "\n",
    "## **1. Why Re-Aggregate Orders (2023 + Q1 2024) When Drift Monitoring?**  \n",
    "When you aggregate **all past data up to the current period**, you assume that past customer behavior is still relevant and contributes to the current segmentation. This is useful when:  \n",
    "\n",
    "- **Customer Behavior is Cumulative** → If customers’ purchasing behavior is persistent (e.g., high-spending customers continue to be high spenders), their full historical transaction history remains important for clustering.  \n",
    "- **Long-Term Trends Matter** → You want to track whether the overall segmentation structure is shifting over time, rather than only detecting short-term fluctuations.  \n",
    "- **Business Needs a Stable Segmentation** → If the marketing team relies on stable customer segments, you want to monitor drift relative to a long-term reference, rather than reacting to short-term seasonal changes.  \n",
    "\n",
    "### **Key Benefit**:  \n",
    "It allows you to detect **gradual drifts** in customer behavior over time, rather than being overly sensitive to short-term fluctuations.  \n",
    "\n",
    "---\n",
    "\n",
    "## **2. Why Use a Rolling Window Instead? (Baseline: 2023, New: Q1 2024 Only)**  \n",
    "Using a rolling window means that you always compare customer behavior over **a fixed recent period** (e.g., last 12 months, or just the last quarter) rather than accumulating all past data.  \n",
    "\n",
    "### **Use This When:**  \n",
    "- **Customer Behavior Changes Rapidly** → If customer purchasing patterns change frequently (e.g., due to seasonality, economic shifts, new product releases).  \n",
    "- **You Want to Detect Sudden Shifts** → This approach is useful for identifying sudden behavioral changes (e.g., if customers stop purchasing or switch to different spending patterns).  \n",
    "- **Recent Data is More Relevant** → In industries where past customer data loses relevance quickly (e.g., fast-moving consumer goods, subscriptions, fashion).  \n",
    "\n",
    "### **Key Benefit**:  \n",
    "It allows you to react **faster** to changes in customer behavior by focusing only on the most recent period.  \n",
    "\n",
    "---\n",
    "\n",
    "## **So, Which Strategy is Better?**  \n",
    "\n",
    "It depends on the business case:  \n",
    "\n",
    "| **Approach** | **Best For** | **Trade-Offs** |\n",
    "|-------------|-------------|---------------|\n",
    "| **Aggregating all past data (2023 + Q1 2024, etc.)** | Businesses with long-term customer relationships where past behavior remains relevant | May be slow to react to sudden changes |\n",
    "| **Rolling window (e.g., baseline 2023, new Q1 2024 only)** | Fast-changing businesses where recent customer activity matters most | May be overly sensitive to short-term fluctuations |\n",
    "\n",
    "---\n",
    "\n",
    "## **How to Choose?**  \n",
    "You can experiment with both methods and track how drift metrics behave:  \n",
    "\n",
    "1. **Compute drift metrics (e.g., Adjusted Rand Index, cluster centroid movement) using both methods**  \n",
    "2. **Compare their sensitivity to changes in customer behavior**  \n",
    "3. **Align with business needs**—if stability is critical, use the full aggregated approach; if rapid detection of changes is needed, use a rolling window.  \n",
    "\n",
    "💡 **Hybrid Approach?**  \n",
    "Some businesses use a **weighted rolling window**, where recent data is given more importance but older data still contributes. For example, weighting transactions so that:  \n",
    "- Orders from the past **6 months** are given full weight (1.0)  \n",
    "- Orders from **6-12 months ago** are given partial weight (e.g., 0.5)  \n",
    "- Orders older than **12 months** are ignored  \n",
    "\n",
    "---\n",
    "\n",
    "## **Final Recommendation**  \n",
    "- If customer behavior is stable over time → **Aggregate all past data**  \n",
    "- If customer behavior shifts frequently → **Use a rolling window**  \n",
    "- If unsure, experiment with **both methods** and evaluate their impact using drift metrics  \n",
    "\n",
    "Would you like a Python example comparing these two methods? 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
